{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Training Skin Disease Classifier\n",
    "\n",
    "Fine-tuning di ResNet50 per la classificazione di patologie cutanee nei cani.\n",
    "\n",
    "## Dataset\n",
    "- **Dog's Skin Diseases** (Kaggle): 4,315 immagini, 6 classi\n",
    "  - Healthy\n",
    "  - Dermatitis\n",
    "  - Fungal_infections\n",
    "  - Hypersensitivity\n",
    "  - Demodicosis\n",
    "  - Ringworm\n",
    "\n",
    "## Output\n",
    "- `P(disease)` ∈ [0, 1] - probabilità di patologia cutanea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installazione dipendenze\n",
    "%pip install torch torchvision timm albumentations matplotlib seaborn pandas scikit-learn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "\n",
    "# Albumentations per data augmentation (come da documentazione)\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURAZIONE HARDWARE - Multi-GPU Support\n",
    "# ============================================================================\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    NUM_GPUS = torch.cuda.device_count()\n",
    "    GPU_NAMES = [torch.cuda.get_device_name(i) for i in range(NUM_GPUS)]\n",
    "    TOTAL_VRAM = sum(torch.cuda.get_device_properties(i).total_memory for i in range(NUM_GPUS)) / 1e9\n",
    "    \n",
    "    print(f\"GPU rilevate: {NUM_GPUS}\")\n",
    "    for i, name in enumerate(GPU_NAMES):\n",
    "        vram = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "        print(f\"   [{i}] {name} ({vram:.1f}GB)\")\n",
    "    \n",
    "    DEVICE = torch.device('cuda')\n",
    "    USE_MULTI_GPU = NUM_GPUS >= 2\n",
    "    \n",
    "    if USE_MULTI_GPU:\n",
    "        print(f\"\\n[OK] Multi-GPU attivo: {NUM_GPUS} GPU\")\n",
    "    \n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "    NUM_GPUS = 1\n",
    "    USE_MULTI_GPU = False\n",
    "    print(\"Apple Silicon MPS\")\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    NUM_GPUS = 0\n",
    "    USE_MULTI_GPU = False\n",
    "    print(\"[WARN] Nessuna GPU, usando CPU\")\n",
    "\n",
    "print(f\"\\nUsing device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione paths - RELATIVI per portabilità\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "try:\n",
    "    from notebook_utils import get_paths, get_device, print_paths\n",
    "    paths = get_paths()\n",
    "    print_paths(paths)\n",
    "except ImportError:\n",
    "    print(\"notebook_utils.py non trovato, usando fallback...\")\n",
    "    NOTEBOOK_DIR = Path.cwd()\n",
    "    if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "        PROJECT_DIR = NOTEBOOK_DIR.parent.parent\n",
    "    elif NOTEBOOK_DIR.name == \"training\":\n",
    "        PROJECT_DIR = NOTEBOOK_DIR.parent\n",
    "    else:\n",
    "        PROJECT_DIR = NOTEBOOK_DIR\n",
    "        while PROJECT_DIR.name != \"ResQPet\" and PROJECT_DIR.parent != PROJECT_DIR:\n",
    "            PROJECT_DIR = PROJECT_DIR.parent\n",
    "    BASE_DIR = PROJECT_DIR.parent\n",
    "    paths = {\n",
    "        'project_dir': PROJECT_DIR,\n",
    "        'base_dir': BASE_DIR,\n",
    "        'weights_dir': PROJECT_DIR / \"backend\" / \"weights\",\n",
    "        'skin_dataset': BASE_DIR / \"Dog's skin diseases\",\n",
    "        'notebooks_dir': PROJECT_DIR / \"training\" / \"notebooks\",\n",
    "    }\n",
    "    paths['weights_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Assegna variabili per retrocompatibilità\n",
    "BASE_DIR = paths['base_dir']\n",
    "DATASET_DIR = paths['skin_dataset']\n",
    "OUTPUT_DIR = paths['weights_dir']\n",
    "\n",
    "print(f\"\\nDataset: {DATASET_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Dataset exists: {DATASET_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Esplorazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "\n",
      "TRAIN:\n",
      "  Healthy: 492\n",
      "  Fungal_infections: 375\n",
      "  ringworm: 791\n",
      "  demodicosis: 588\n",
      "  Hypersensitivity: 230\n",
      "  Dermatitis: 546\n",
      "  TOTAL: 3022\n",
      "\n",
      "VALID:\n",
      "  Healthy: 139\n",
      "  Fungal_infections: 97\n",
      "  ringworm: 212\n",
      "  demodicosis: 174\n",
      "  Hypersensitivity: 63\n",
      "  Dermatitis: 175\n",
      "  TOTAL: 860\n",
      "\n",
      "TEST:\n",
      "  Healthy: 69\n",
      "  Fungal_infections: 54\n",
      "  ringworm: 115\n",
      "  demodicosis: 100\n",
      "  Hypersensitivity: 29\n",
      "  Dermatitis: 66\n",
      "  TOTAL: 433\n"
     ]
    }
   ],
   "source": [
    "# Esplora struttura dataset\n",
    "def explore_dataset(dataset_dir):\n",
    "    stats = {}\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_dir = dataset_dir / split\n",
    "        if not split_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        stats[split] = {}\n",
    "        \n",
    "        for class_dir in split_dir.iterdir():\n",
    "            if class_dir.is_dir():\n",
    "                images = list(class_dir.glob('*.*'))\n",
    "                stats[split][class_dir.name] = len(images)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "dataset_stats = explore_dataset(DATASET_DIR)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "for split, classes in dataset_stats.items():\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    total = 0\n",
    "    for cls, count in classes.items():\n",
    "        print(f\"  {cls}: {count}\")\n",
    "        total += count\n",
    "    print(f\"  TOTAL: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci classi e mapping - ORDINE ESPLICITO come da documentazione\n",
    "# IMPORTANTE: Healthy DEVE essere classe 0 per il calcolo P(disease) = 1 - P(Healthy)\n",
    "CLASS_NAMES = ['Healthy', 'Dermatitis', 'Fungal_infections', 'Hypersensitivity', 'demodicosis', 'ringworm']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "CLASS_TO_IDX = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "IDX_TO_CLASS = {idx: cls for cls, idx in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(f\"Classi (ordine fisso): {CLASS_NAMES}\")\n",
    "print(f\"Numero classi: {NUM_CLASSES}\")\n",
    "print(f\"Mapping: {CLASS_TO_IDX}\")\n",
    "\n",
    "# Disease severity (per calcolo P(disease))\n",
    "DISEASE_WEIGHTS = {\n",
    "    'Healthy': 0.0,\n",
    "    'Dermatitis': 0.6,\n",
    "    'Fungal_infections': 0.7,\n",
    "    'Hypersensitivity': 0.4,\n",
    "    'demodicosis': 0.8,\n",
    "    'ringworm': 0.75\n",
    "}\n",
    "\n",
    "print(f\"\\nDisease weights: {DISEASE_WEIGHTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza distribuzione classi\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, (split, classes) in enumerate(dataset_stats.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.bar(classes.keys(), classes.values())\n",
    "    ax.set_title(f'{split.upper()} Distribution')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths['notebooks_dir'] / 'skin_class_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza esempi per classe\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, class_name in enumerate(CLASS_NAMES[:6]):\n",
    "    class_dir = DATASET_DIR / 'train' / class_name\n",
    "    if class_dir.exists():\n",
    "        images = list(class_dir.glob('*.*'))[:1]\n",
    "        if images:\n",
    "            img = cv2.imread(str(images[0]))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(class_name)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths['notebooks_dir'] / 'skin_samples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset e DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDiseaseDataset(Dataset):\n",
    "    \"\"\"Dataset per classificazione patologie cutanee - compatibile con Albumentations\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = Path(root_dir) / split\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        # Carica tutti i campioni\n",
    "        for class_dir in self.root_dir.iterdir():\n",
    "            if class_dir.is_dir() and class_dir.name in CLASS_TO_IDX:\n",
    "                class_idx = CLASS_TO_IDX[class_dir.name]\n",
    "                for img_path in class_dir.glob('*.*'):\n",
    "                    if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                        self.samples.append((str(img_path), class_idx))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples from {split}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Carica immagine come numpy array (per Albumentations)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            # Albumentations usa dizionario con chiave 'image'\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms con Albumentations (come da documentazione)\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.1,\n",
    "        p=0.5\n",
    "    ),\n",
    "    A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "print(\"Transforms Albumentations definiti (come da documentazione)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea dataset\n",
    "train_dataset = SkinDiseaseDataset(DATASET_DIR, split='train', transform=train_transform)\n",
    "val_dataset = SkinDiseaseDataset(DATASET_DIR, split='valid', transform=val_transform)\n",
    "test_dataset = SkinDiseaseDataset(DATASET_DIR, split='test', transform=val_transform)\n",
    "\n",
    "# ============================================================================\n",
    "# DataLoaders - Batch size scalato per multi-GPU\n",
    "# NOTA: NUM_WORKERS = 0 per evitare problemi di multiprocessing nei container\n",
    "# ============================================================================\n",
    "if torch.cuda.is_available() and NUM_GPUS >= 2:\n",
    "    BATCH_SIZE = 64 * NUM_GPUS  # 64 per GPU\n",
    "    print(f\"[OK] Multi-GPU: batch_size={BATCH_SIZE} ({64} x {NUM_GPUS} GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    BATCH_SIZE = 64\n",
    "else:\n",
    "    BATCH_SIZE = 32\n",
    "# IMPORTANTE: num_workers=0 evita errori multiprocessing in container/server\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Workers: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modello ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea modello con timm\n",
    "def create_model(num_classes, pretrained=True):\n",
    "    \"\"\"Crea ResNet50 con classification head custom\"\"\"\n",
    "    model = timm.create_model(\n",
    "        'resnet50',\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def freeze_backbone(model):\n",
    "    \"\"\"Congela il backbone, lascia trainabile solo il classifier head\"\"\"\n",
    "    # Se DataParallel, accedi al modulo interno\n",
    "    m = model.module if hasattr(model, 'module') else model\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'fc' not in name:  # 'fc' e il classification head in ResNet\n",
    "            param.requires_grad = False\n",
    "    print(\"Backbone congelato - solo classifier head trainabile\")\n",
    "\n",
    "def unfreeze_backbone(model):\n",
    "    \"\"\"Sblocca tutti i parametri per fine-tuning\"\"\"\n",
    "    m = model.module if hasattr(model, 'module') else model\n",
    "    for param in m.parameters():\n",
    "        param.requires_grad = True\n",
    "    print(\"Backbone sbloccato - fine-tuning completo\")\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    \"\"\"Conta parametri trainabili\"\"\"\n",
    "    m = model.module if hasattr(model, 'module') else model\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "# Crea modello\n",
    "model = create_model(NUM_CLASSES, pretrained=True)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ============================================================================\n",
    "# Multi-GPU: DataParallel wrapper\n",
    "# ============================================================================\n",
    "if USE_MULTI_GPU:\n",
    "    model = nn.DataParallel(model)\n",
    "    print(f\"[OK] DataParallel attivo su {NUM_GPUS} GPU\")\n",
    "\n",
    "print(f\"\\nModel created: ResNet50\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable: {count_trainable_params(model):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (come da documentazione)\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001       # LR alto per fase 1 (backbone frozen)\n",
    "FINE_TUNE_LR = 1e-5         # LR basso per fase 2 (fine-tuning)\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 10\n",
    "\n",
    "# Freeze strategy (come da documentazione)\n",
    "FREEZE_BACKBONE = True      # Fase 1: backbone congelato\n",
    "UNFREEZE_EPOCH = 10         # Sblocca dopo 10 epoche\n",
    "\n",
    "print(f\"Training config:\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Fase 1 (epochs 1-{UNFREEZE_EPOCH}): backbone frozen, LR={LEARNING_RATE}\")\n",
    "print(f\"  - Fase 2 (epochs {UNFREEZE_EPOCH+1}-{EPOCHS}): fine-tuning, LR={FINE_TUNE_LR}\")\n",
    "\n",
    "# Class weights per dataset sbilanciato\n",
    "train_counts = [sum(1 for s in train_dataset.samples if s[1] == i) for i in range(NUM_CLASSES)]\n",
    "class_weights = torch.FloatTensor([max(train_counts) / c for c in train_counts]).to(DEVICE)\n",
    "print(f\"\\nClass weights: {class_weights}\")\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Congela backbone per fase 1\n",
    "if FREEZE_BACKBONE:\n",
    "    freeze_backbone(model)\n",
    "    print(f\"\\nParametri trainabili (fase 1): {count_trainable_params(model):,}\")\n",
    "\n",
    "# Optimizer - solo parametri trainabili\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "    lr=LEARNING_RATE, \n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training loop con two-phase freeze/unfreeze strategy\nprint(\"=\"*50)\nprint(\"INIZIO TRAINING SKIN CLASSIFIER\")\nprint(\"=\"*50)\nprint(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"\\nStrategia: Two-phase training\")\nprint(f\"  Fase 1 (epoch 1-{UNFREEZE_EPOCH}): Backbone frozen, LR={LEARNING_RATE}\")\nprint(f\"  Fase 2 (epoch {UNFREEZE_EPOCH+1}+): Fine-tuning completo, LR={FINE_TUNE_LR}\")\nprint()\n\nhistory = {\n    'train_loss': [], 'train_acc': [],\n    'val_loss': [], 'val_acc': [], 'val_f1': []\n}\n\nbest_f1 = 0\npatience_counter = 0\nbest_model_path = OUTPUT_DIR / 'skin_classifier_best.pt'\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    \n    # ===== FASE 2: Unfreeze backbone dopo UNFREEZE_EPOCH =====\n    if epoch == UNFREEZE_EPOCH:\n        print(\"\\n\" + \"=\"*40)\n        print(\"FASE 2: Fine-tuning completo\")\n        print(\"=\"*40)\n        \n        # Sblocca backbone\n        unfreeze_backbone(model)\n        print(f\"Parametri trainabili: {count_trainable_params(model):,}\")\n        \n        # Nuovo optimizer con LR ridotto per fine-tuning\n        optimizer = optim.AdamW(\n            model.parameters(), \n            lr=FINE_TUNE_LR, \n            weight_decay=WEIGHT_DECAY\n        )\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n        print(f\"Nuovo LR: {FINE_TUNE_LR}\")\n        print()\n    \n    # Train\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n    \n    # Validate\n    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, DEVICE)\n    \n    # Update scheduler\n    scheduler.step(val_loss)\n    \n    # Log\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    history['val_f1'].append(val_f1)\n    \n    phase = \"Fase 1 (frozen)\" if epoch < UNFREEZE_EPOCH else \"Fase 2 (fine-tune)\"\n    print(f\"  [{phase}]\")\n    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n    \n    # Save best model - GESTISCE DATAPARALLEL\n    if val_f1 > best_f1:\n        best_f1 = val_f1\n        patience_counter = 0\n        # Estrai state_dict senza prefisso 'module.' per compatibilità\n        model_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model_state,\n            'optimizer_state_dict': optimizer.state_dict(),\n            'val_f1': val_f1,\n            'val_acc': val_acc,\n            'class_names': CLASS_NAMES,\n            'num_classes': NUM_CLASSES\n        }, best_model_path)\n        print(f\"  ✓ Best model saved (F1: {val_f1:.4f})\")\n    else:\n        patience_counter += 1\n        # Early stopping solo dopo fase 2\n        if patience_counter >= PATIENCE and epoch >= UNFREEZE_EPOCH:\n            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n            break\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"TRAINING COMPLETATO!\")\nprint(\"=\"*50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Valutazione Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica best model\n",
    "# NOTA: weights_only=False necessario per PyTorch 2.6+\n",
    "checkpoint = torch.load(best_model_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Val F1: {checkpoint['val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test finale\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths['notebooks_dir'] / 'skin_confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['val_acc'], label='Val')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "# F1\n",
    "axes[2].plot(history['val_f1'], label='Val F1')\n",
    "axes[2].set_title('Validation F1 Score')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths['notebooks_dir'] / 'skin_training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Salva modello finale - GESTISCE DATAPARALLEL\nfinal_model_path = OUTPUT_DIR / 'skin_classifier.pt'\n\n# Estrai state_dict senza prefisso 'module.' per compatibilità\nmodel_state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n\ntorch.save({\n    'model_state_dict': model_state,\n    'class_names': CLASS_NAMES,\n    'num_classes': NUM_CLASSES,\n    'disease_weights': DISEASE_WEIGHTS,\n    'test_accuracy': test_acc,\n    'test_f1': test_f1\n}, final_model_path)\n\nprint(f\"Modello salvato in: {final_model_path}\")\nprint(f\"Dimensione: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test del modello esportato\n",
    "print(\"\\nTest modello esportato...\")\n",
    "\n",
    "# Carica modello (weights_only=False per PyTorch 2.6+)\n",
    "loaded_checkpoint = torch.load(final_model_path, weights_only=False)\n",
    "test_model = create_model(loaded_checkpoint['num_classes'], pretrained=False)\n",
    "test_model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
    "test_model.eval()\n",
    "\n",
    "# Test su un'immagine\n",
    "test_img_path = list((DATASET_DIR / 'test' / CLASS_NAMES[0]).glob('*.*'))[0]\n",
    "test_img = Image.open(test_img_path).convert('RGB')\n",
    "test_tensor = val_transform(test_img).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = test_model(test_tensor)\n",
    "    probs = torch.softmax(output, dim=1)[0]\n",
    "    pred_idx = probs.argmax().item()\n",
    "    pred_class = CLASS_NAMES[pred_idx]\n",
    "    pred_conf = probs[pred_idx].item()\n",
    "\n",
    "print(f\"\\nTest image: {test_img_path.name}\")\n",
    "print(f\"Prediction: {pred_class} ({pred_conf:.2%})\")\n",
    "print(f\"\\nProbabilità per classe:\")\n",
    "for i, cls in enumerate(CLASS_NAMES):\n",
    "    print(f\"  {cls}: {probs[i].item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riepilogo finale\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RIEPILOGO TRAINING SKIN CLASSIFIER\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nDataset: {DATASET_DIR}\")\n",
    "print(f\"  - Classi: {NUM_CLASSES}\")\n",
    "print(f\"  - Train samples: {len(train_dataset)}\")\n",
    "print(f\"  - Val samples: {len(val_dataset)}\")\n",
    "print(f\"  - Test samples: {len(test_dataset)}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  - Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"  - Best epoch: {checkpoint['epoch']+1}\")\n",
    "print(f\"\\nRisultati Test:\")\n",
    "print(f\"  - Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  - F1 Score: {test_f1:.4f}\")\n",
    "print(f\"\\nModello salvato: {final_model_path}\")\n",
    "print(\"\\nProssimo step: 03_pose_training.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}