{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Training Breed Classifier\n",
    "\n",
    "Fine-tuning di EfficientNet-B0 per la classificazione delle razze canine.\n",
    "\n",
    "## Dataset\n",
    "- **Stanford Dogs Dataset**: 120 razze, ~20,580 immagini\n",
    "- Alternativa: subset delle razze pi√π comuni nei canili italiani\n",
    "\n",
    "## Output\n",
    "- Classificazione razza ‚Üí mapping a `P(stray|breed)` usando i prior statistici\n",
    "\n",
    "## Strategia\n",
    "1. Raggruppiamo le 120 razze in macro-categorie (pitbull, shepherd, retriever, etc.)\n",
    "2. Questo semplifica il problema e allinea con i breed_priors.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione dipendenze\n",
    "%pip install torch torchvision timm albumentations matplotlib seaborn pandas scikit-learn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\nimport json\nimport shutil\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom collections import defaultdict\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(f\"Python: {sys.version}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"Device: {'MPS' if torch.backends.mps.is_available() else 'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configurazione paths - RELATIVI per portabilit√†\nimport sys\nsys.path.insert(0, str(Path.cwd()))\ntry:\n    from notebook_utils import get_paths, get_device, print_paths\n    paths = get_paths()\n    print_paths(paths)\nexcept ImportError:\n    print(\"notebook_utils.py non trovato, usando fallback...\")\n    NOTEBOOK_DIR = Path.cwd()\n    if NOTEBOOK_DIR.name == \"notebooks\":\n        PROJECT_DIR = NOTEBOOK_DIR.parent.parent\n    elif NOTEBOOK_DIR.name == \"training\":\n        PROJECT_DIR = NOTEBOOK_DIR.parent\n    else:\n        PROJECT_DIR = NOTEBOOK_DIR\n        while PROJECT_DIR.name != \"ResQPet\" and PROJECT_DIR.parent != PROJECT_DIR:\n            PROJECT_DIR = PROJECT_DIR.parent\n    BASE_DIR = PROJECT_DIR.parent\n    paths = {\n        'project_dir': PROJECT_DIR,\n        'base_dir': BASE_DIR,\n        'weights_dir': PROJECT_DIR / \"backend\" / \"weights\",\n        'data_dir': PROJECT_DIR / \"data\",\n        'stanford_dogs': BASE_DIR / \"Stanford Dog\",\n    }\n    paths['weights_dir'].mkdir(parents=True, exist_ok=True)\n\n# Assegna variabili per retrocompatibilit√†\nBASE_DIR = paths['base_dir']\nSTANFORD_DIR = paths['stanford_dogs']\nPRIORS_FILE = paths['data_dir'] / \"breed_priors.json\"\nOUTPUT_DIR = paths['weights_dir']\n\n# Carica breed priors\nif PRIORS_FILE.exists():\n    with open(PRIORS_FILE, 'r') as f:\n        breed_priors = json.load(f)\n    print(\"Breed Priors (P(stray|breed)):\")\n    for breed, prob in breed_priors.items():\n        if breed != '_metadata':\n            print(f\"  {breed}: {prob}\")\nelse:\n    print(f\"‚ö†Ô∏è breed_priors.json non trovato in {PRIORS_FILE}\")\n    breed_priors = {'unknown': 0.5}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mapping Razze ‚Üí Macro-Categorie\n",
    "\n",
    "Stanford Dogs ha 120 razze specifiche. Le raggruppiamo nelle categorie usate per i prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping da razze Stanford Dogs a macro-categorie\n",
    "# Le razze Stanford usano formato: \"n02085620-Chihuahua\" (synset-nome)\n",
    "\n",
    "BREED_MAPPING = {\n",
    "    # Pitbull/Amstaff - razze spesso in canile\n",
    "    'pitbull_amstaff': [\n",
    "        'American_Staffordshire_terrier', 'Staffordshire_bullterrier',\n",
    "        'bull_mastiff', 'boxer', 'Great_Dane'\n",
    "    ],\n",
    "    \n",
    "    # Pastori\n",
    "    'shepherd': [\n",
    "        'German_shepherd', 'Belgian_malinois', 'Australian_shepherd',\n",
    "        'Border_collie', 'collie', 'Shetland_sheepdog', 'Old_English_sheepdog',\n",
    "        'Bouvier_des_Flandres', 'briard', 'kelpie', 'komondor', 'kuvasz'\n",
    "    ],\n",
    "    \n",
    "    # Retriever e cani da caccia\n",
    "    'retriever': [\n",
    "        'golden_retriever', 'Labrador_retriever', 'flat-coated_retriever',\n",
    "        'curly-coated_retriever', 'Chesapeake_Bay_retriever',\n",
    "        'Irish_setter', 'English_setter', 'Gordon_setter',\n",
    "        'cocker_spaniel', 'English_springer', 'Welsh_springer_spaniel',\n",
    "        'clumber', 'Sussex_spaniel', 'Irish_water_spaniel',\n",
    "        'vizsla', 'Weimaraner', 'German_short-haired_pointer'\n",
    "    ],\n",
    "    \n",
    "    # Segugi\n",
    "    'hound': [\n",
    "        'beagle', 'basset', 'bloodhound', 'bluetick', 'redbone',\n",
    "        'Walker_hound', 'English_foxhound', 'borzoi', 'Irish_wolfhound',\n",
    "        'Scottish_deerhound', 'whippet', 'Ibizan_hound', 'Afghan_hound',\n",
    "        'saluki', 'otterhound', 'black-and-tan_coonhound', 'Rhodesian_ridgeback',\n",
    "        'dingo', 'basenji', 'Norwegian_elkhound'\n",
    "    ],\n",
    "    \n",
    "    # Terrier\n",
    "    'terrier': [\n",
    "        'Airedale', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier',\n",
    "        'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier',\n",
    "        'wire-haired_fox_terrier', 'Lakeland_terrier', 'Sealyham_terrier',\n",
    "        'Scottish_terrier', 'Tibetan_terrier', 'silky_terrier', 'wheaten_terrier',\n",
    "        'West_Highland_white_terrier', 'Lhasa', 'cairn', 'Australian_terrier',\n",
    "        'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer',\n",
    "        'standard_schnauzer', 'soft-coated_wheaten_terrier'\n",
    "    ],\n",
    "    \n",
    "    # Toy/piccola taglia\n",
    "    'toy': [\n",
    "        'Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese',\n",
    "        'Shih-Tzu', 'Blenheim_spaniel', 'papillon', 'toy_terrier',\n",
    "        'miniature_pinscher', 'affenpinscher', 'toy_poodle', 'Pomeranian',\n",
    "        'pug', 'Italian_greyhound'\n",
    "    ],\n",
    "    \n",
    "    # Working dogs\n",
    "    'working': [\n",
    "        'Siberian_husky', 'Alaskan_malamute', 'Eskimo_dog', 'Saint_Bernard',\n",
    "        'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller',\n",
    "        'EntleBucher', 'Rottweiler', 'Doberman', 'miniature_pinscher',\n",
    "        'Great_Pyrenees', 'Leonberg', 'Newfoundland', 'Tibetan_mastiff'\n",
    "    ],\n",
    "    \n",
    "    # Spitz\n",
    "    'spitz': [\n",
    "        'chow', 'keeshond', 'Pomeranian', 'Samoyed', 'schipperke',\n",
    "        'Shiba_inu', 'Akita'\n",
    "    ],\n",
    "    \n",
    "    # Bulldog\n",
    "    'bulldog': [\n",
    "        'French_bulldog', 'English_bulldog'\n",
    "    ],\n",
    "    \n",
    "    # Poodle\n",
    "    'poodle': [\n",
    "        'standard_poodle', 'miniature_poodle', 'toy_poodle'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Inverti il mapping per lookup veloce\n",
    "BREED_TO_CATEGORY = {}\n",
    "for category, breeds in BREED_MAPPING.items():\n",
    "    for breed in breeds:\n",
    "        BREED_TO_CATEGORY[breed.lower()] = category\n",
    "\n",
    "# Lista categorie\n",
    "CATEGORIES = list(BREED_MAPPING.keys()) + ['mixed', 'unknown']\n",
    "CATEGORY_TO_IDX = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n",
    "IDX_TO_CATEGORY = {idx: cat for cat, idx in CATEGORY_TO_IDX.items()}\n",
    "\n",
    "print(f\"\\nCategorie: {CATEGORIES}\")\n",
    "print(f\"Numero categorie: {len(CATEGORIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Esplorazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerca il dataset Stanford Dogs\n",
    "# Pu√≤ essere in formato diverso a seconda di come √® stato scaricato\n",
    "\n",
    "def find_stanford_images(base_dir):\n",
    "    \"\"\"Trova le immagini del dataset Stanford Dogs\"\"\"\n",
    "    images = []\n",
    "    \n",
    "    # Pattern 1: Kaggle format (Images/breed_name/image.jpg)\n",
    "    images_dir = base_dir / \"Images\"\n",
    "    if images_dir.exists():\n",
    "        for breed_dir in images_dir.iterdir():\n",
    "            if breed_dir.is_dir():\n",
    "                breed_name = breed_dir.name.split('-')[-1] if '-' in breed_dir.name else breed_dir.name\n",
    "                for img_path in breed_dir.glob('*.jpg'):\n",
    "                    images.append((img_path, breed_name))\n",
    "        return images\n",
    "    \n",
    "    # Pattern 2: Flat structure\n",
    "    for img_path in base_dir.rglob('*.jpg'):\n",
    "        # Estrai nome razza dal path\n",
    "        breed_name = img_path.parent.name.split('-')[-1]\n",
    "        images.append((img_path, breed_name))\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Prova a trovare le immagini\n",
    "if STANFORD_DIR.exists():\n",
    "    all_images = find_stanford_images(STANFORD_DIR)\n",
    "    print(f\"Trovate {len(all_images)} immagini\")\n",
    "    \n",
    "    # Conta per razza\n",
    "    breed_counts = defaultdict(int)\n",
    "    for _, breed in all_images:\n",
    "        breed_counts[breed] += 1\n",
    "    \n",
    "    print(f\"\\nRazze trovate: {len(breed_counts)}\")\n",
    "    print(\"\\nTop 10 razze per numero immagini:\")\n",
    "    for breed, count in sorted(breed_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "        print(f\"  {breed}: {count}\")\n",
    "else:\n",
    "    print(f\"Dataset non trovato in {STANFORD_DIR}\")\n",
    "    print(\"\\nPer scaricare:\")\n",
    "    print(\"1. Kaggle: https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\")\n",
    "    print(\"2. Originale: http://vision.stanford.edu/aditya86/ImageNetDogs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappa le razze alle categorie\n",
    "def map_breed_to_category(breed_name):\n",
    "    \"\"\"Mappa una razza alla sua macro-categoria\"\"\"\n",
    "    breed_lower = breed_name.lower().replace('-', '_').replace(' ', '_')\n",
    "    \n",
    "    # Cerca match esatto\n",
    "    if breed_lower in BREED_TO_CATEGORY:\n",
    "        return BREED_TO_CATEGORY[breed_lower]\n",
    "    \n",
    "    # Cerca match parziale\n",
    "    for key, category in BREED_TO_CATEGORY.items():\n",
    "        if key in breed_lower or breed_lower in key:\n",
    "            return category\n",
    "    \n",
    "    # Default a 'mixed' per razze non mappate\n",
    "    return 'mixed'\n",
    "\n",
    "# Test mapping\n",
    "test_breeds = ['golden_retriever', 'German_shepherd', 'Chihuahua', 'pug', 'beagle']\n",
    "print(\"Test mapping razze:\")\n",
    "for breed in test_breeds:\n",
    "    category = map_breed_to_category(breed)\n",
    "    print(f\"  {breed} ‚Üí {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea dataset con categorie\n",
    "if STANFORD_DIR.exists() and all_images:\n",
    "    # Mappa immagini a categorie\n",
    "    categorized_images = []\n",
    "    category_counts = defaultdict(int)\n",
    "    \n",
    "    for img_path, breed in all_images:\n",
    "        category = map_breed_to_category(breed)\n",
    "        categorized_images.append((img_path, category))\n",
    "        category_counts[category] += 1\n",
    "    \n",
    "    print(\"Distribuzione per categoria:\")\n",
    "    for cat, count in sorted(category_counts.items(), key=lambda x: -x[1]):\n",
    "        prior = breed_priors.get(cat, 0.5)\n",
    "        print(f\"  {cat}: {count} immagini (P(stray)={prior})\")\n",
    "    \n",
    "    # Visualizza distribuzione\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    cats = list(category_counts.keys())\n",
    "    counts = [category_counts[c] for c in cats]\n",
    "    priors = [breed_priors.get(c, 0.5) for c in cats]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(cats, counts, color='steelblue')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Immagini per Categoria')\n",
    "    plt.ylabel('Numero immagini')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    colors = plt.cm.RdYlGn_r(np.array(priors))\n",
    "    plt.bar(cats, priors, color=colors)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('P(stray|breed) per Categoria')\n",
    "    plt.ylabel('Probabilit√† randagio')\n",
    "    plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR.parent.parent / 'training' / 'notebooks' / 'breed_distribution.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparazione Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class BreedDataset(Dataset):\n    \"\"\"Dataset per classificazione razze canine (Albumentations)\"\"\"\n    \n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        \n        # Carica immagine come numpy array per Albumentations\n        try:\n            image = Image.open(img_path).convert('RGB')\n            image = np.array(image)\n        except Exception as e:\n            print(f\"Errore caricamento {img_path}: {e}\")\n            # Ritorna immagine placeholder\n            image = np.zeros((224, 224, 3), dtype=np.uint8)\n        \n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed['image']\n        \n        return image, label"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Trasformazioni con Albumentations\nIMG_SIZE = 224\n\ntrain_transform = A.Compose([\n    A.Resize(256, 256),\n    A.RandomCrop(IMG_SIZE, IMG_SIZE),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(limit=15, p=0.5),\n    A.ColorJitter(\n        brightness=0.2,\n        contrast=0.2,\n        saturation=0.2,\n        hue=0.05,\n        p=0.5\n    ),\n    A.CoarseDropout(\n        max_holes=8,\n        max_height=16,\n        max_width=16,\n        p=0.3\n    ),\n    A.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE),\n    A.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n    ToTensorV2()\n])\n\nprint(\"Trasformazioni Albumentations definite\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Split dataset\nif STANFORD_DIR.exists() and categorized_images:\n    # Prepara liste\n    all_paths = [str(img[0]) for img in categorized_images]\n    all_labels = [CATEGORY_TO_IDX[img[1]] for img in categorized_images]\n    \n    # Split stratificato\n    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n        all_paths, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n    )\n    \n    val_paths, test_paths, val_labels, test_labels = train_test_split(\n        temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n    )\n    \n    print(f\"Train: {len(train_paths)} immagini\")\n    print(f\"Val: {len(val_paths)} immagini\")\n    print(f\"Test: {len(test_paths)} immagini\")\n    \n    # Crea dataset\n    train_dataset = BreedDataset(train_paths, train_labels, train_transform)\n    val_dataset = BreedDataset(val_paths, val_labels, val_transform)\n    test_dataset = BreedDataset(test_paths, test_labels, val_transform)\n    \n    # DataLoaders\n    # NOTA: num_workers=0 su macOS per evitare problemi di multiprocessing\n    BATCH_SIZE = 32\n    NUM_WORKERS = 0\n    \n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n    \n    print(f\"\\nBatch size: {BATCH_SIZE}\")\n    print(f\"Train batches: {len(train_loader)}\")\n    print(f\"Val batches: {len(val_loader)}\")\n    print(f\"Num workers: {NUM_WORKERS}\")\nelse:\n    print(\"Dataset non disponibile - usando dati sintetici per demo\")\n    # Crea dati sintetici per test del codice\n    train_loader = None\n    val_loader = None\n    test_loader = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definizione Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreedClassifier(nn.Module):\n",
    "    \"\"\"EfficientNet-B0 per classificazione razze\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int, pretrained: bool = True, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone EfficientNet-B0\n",
    "        self.backbone = timm.create_model(\n",
    "            'efficientnet_b0',\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0  # Rimuove classifier\n",
    "        )\n",
    "        \n",
    "        # Feature dimension\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        \n",
    "        # Custom classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone(x)\n",
    "        # Classify\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Ritorna probabilit√† per ogni classe\"\"\"\n",
    "        logits = self.forward(x)\n",
    "        return torch.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza modello\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "\n",
    "model = BreedClassifier(num_classes=NUM_CLASSES, pretrained=True, dropout=0.3)\n",
    "\n",
    "# Device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Classi: {NUM_CLASSES}\")\n",
    "print(f\"Feature dim: {model.feature_dim}\")\n",
    "print(f\"\\nParametri totali: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Parametri trainabili: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione training\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Loss con class weights per dataset sbilanciato\n",
    "if train_loader:\n",
    "    # Calcola pesi per classi\n",
    "    class_counts = np.bincount(train_labels, minlength=NUM_CLASSES)\n",
    "    class_weights = 1.0 / (class_counts + 1)  # +1 per evitare divisione per zero\n",
    "    class_weights = class_weights / class_weights.sum() * NUM_CLASSES\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "else:\n",
    "    class_weights = None\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer con learning rate differenziato\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.backbone.parameters(), 'lr': LEARNING_RATE * 0.1},  # Backbone: LR basso\n",
    "    {'params': model.classifier.parameters(), 'lr': LEARNING_RATE}       # Classifier: LR alto\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(f\"\\nConfigurazione training:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Weight decay: {WEIGHT_DECAY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Training per una epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validazione\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING LOOP\n",
    "if train_loader:\n",
    "    print(\"=\"*50)\n",
    "    print(\"INIZIO TRAINING BREED CLASSIFIER\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Log\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'categories': CATEGORIES,\n",
    "                'category_to_idx': CATEGORY_TO_IDX,\n",
    "                'breed_priors': breed_priors\n",
    "            }, OUTPUT_DIR / 'breed_classifier_best.pt')\n",
    "            print(f\"üíæ Nuovo best model salvato! (acc={val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING COMPLETATO!\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"Nessun dato disponibile per training\")\n",
    "    print(\"Saltando alla sezione di export modello placeholder...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza curve training\n",
    "if train_loader and history['train_loss']:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Validation')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Validation')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training Accuracy')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR.parent.parent / 'training' / 'notebooks' / 'breed_training_curves.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Valutazione su Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if test_loader:\n    # Carica best model (weights_only=False per PyTorch 2.6+)\n    best_path = OUTPUT_DIR / 'breed_classifier_best.pt'\n    if best_path.exists():\n        checkpoint = torch.load(best_path, map_location=device, weights_only=False)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        print(f\"Best model caricato (epoch {checkpoint['epoch']}, acc={checkpoint['val_acc']:.2f}%)\")\n    \n    # Valutazione\n    test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion, device)\n    \n    print(f\"\\nTest Results:\")\n    print(f\"  Loss: {test_loss:.4f}\")\n    print(f\"  Accuracy: {test_acc:.2f}%\")\n    \n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(test_labels, test_preds, target_names=CATEGORIES, zero_division=0))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "if test_loader:\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix - Breed Categories')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR.parent.parent / 'training' / 'notebooks' / 'breed_confusion_matrix.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Modello per Produzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva modello finale per il backend\n",
    "final_model_path = OUTPUT_DIR / 'breed_classifier.pt'\n",
    "\n",
    "# Se abbiamo trainato, usa il best model\n",
    "best_path = OUTPUT_DIR / 'breed_classifier_best.pt'\n",
    "if best_path.exists():\n",
    "    shutil.copy(best_path, final_model_path)\n",
    "    print(f\"Modello trainato copiato in: {final_model_path}\")\n",
    "else:\n",
    "    # Salva modello pre-trained (non fine-tuned)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'categories': CATEGORIES,\n",
    "        'category_to_idx': CATEGORY_TO_IDX,\n",
    "        'idx_to_category': IDX_TO_CATEGORY,\n",
    "        'breed_priors': breed_priors,\n",
    "        'note': 'Modello non fine-tuned - usare euristiche'\n",
    "    }, final_model_path)\n",
    "    print(f\"Modello placeholder salvato in: {final_model_path}\")\n",
    "\n",
    "# Salva anche il mapping\n",
    "mapping_path = OUTPUT_DIR.parent.parent / 'data' / 'breed_mapping.json'\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'categories': CATEGORIES,\n",
    "        'category_to_idx': CATEGORY_TO_IDX,\n",
    "        'breed_mapping': BREED_MAPPING\n",
    "    }, f, indent=2)\n",
    "print(f\"Mapping salvato in: {mapping_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test modello esportato\nprint(\"\\nTest modello esportato...\")\n\n# Carica (weights_only=False per PyTorch 2.6+)\ncheckpoint = torch.load(final_model_path, map_location=device, weights_only=False)\n\ntest_model = BreedClassifier(num_classes=len(checkpoint['categories']))\ntest_model.load_state_dict(checkpoint['model_state_dict'])\ntest_model.to(device)\ntest_model.eval()\n\n# Test con immagine random\ntest_input = torch.randn(1, 3, 224, 224).to(device)\nwith torch.no_grad():\n    output = test_model.predict_proba(test_input)\n\nprint(f\"\\nOutput shape: {output.shape}\")\nprint(f\"\\nProbabilit√† per categoria (test random):\")\nfor idx, prob in enumerate(output[0].cpu().numpy()):\n    cat = checkpoint['categories'][idx]\n    stray_prior = checkpoint['breed_priors'].get(cat, 0.5)\n    print(f\"  {cat}: {prob:.4f} (P(stray|breed)={stray_prior})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione helper per ottenere P(stray|breed)\n",
    "def get_stray_probability_from_breed(model, image_tensor, breed_priors, device):\n",
    "    \"\"\"\n",
    "    Dato un'immagine, predice la categoria di razza e ritorna P(stray|breed)\n",
    "    \n",
    "    Returns:\n",
    "        predicted_category: str - categoria predetta\n",
    "        category_prob: float - confidenza nella predizione\n",
    "        stray_prob: float - P(stray|breed) dalla tabella prior\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        probs = model.predict_proba(image_tensor)\n",
    "        \n",
    "        # Categoria pi√π probabile\n",
    "        top_prob, top_idx = probs.max(dim=1)\n",
    "        predicted_category = CATEGORIES[top_idx.item()]\n",
    "        category_prob = top_prob.item()\n",
    "        \n",
    "        # Prior per la categoria\n",
    "        stray_prob = breed_priors.get(predicted_category, 0.5)\n",
    "        \n",
    "        return predicted_category, category_prob, stray_prob\n",
    "\n",
    "# Test\n",
    "cat, conf, stray = get_stray_probability_from_breed(\n",
    "    test_model, test_input, breed_priors, device\n",
    ")\n",
    "print(f\"\\nPredizione: {cat} (conf={conf:.2%})\")\n",
    "print(f\"P(stray|{cat}) = {stray}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riepilogo finale\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RIEPILOGO BREED CLASSIFIER\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nArchitettura: EfficientNet-B0\")\n",
    "print(f\"Categorie: {len(CATEGORIES)}\")\n",
    "for cat in CATEGORIES:\n",
    "    prior = breed_priors.get(cat, 0.5)\n",
    "    print(f\"  - {cat}: P(stray)={prior}\")\n",
    "\n",
    "if train_loader and 'best_val_acc' in dir():\n",
    "    print(f\"\\nTraining completato:\")\n",
    "    print(f\"  Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    if 'test_acc' in dir():\n",
    "        print(f\"  Test accuracy: {test_acc:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\nModello non fine-tuned\")\n",
    "    print(\"  Il backend user√† euristiche fino al training\")\n",
    "\n",
    "print(f\"\\nFile salvati:\")\n",
    "print(f\"  - {final_model_path}\")\n",
    "print(f\"  - {mapping_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}