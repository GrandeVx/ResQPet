{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Training Collar Detector\n",
    "\n",
    "Fine-tuning di YOLOv8n per la detection di collare/guinzaglio sui cani.\n",
    "\n",
    "## Dataset\n",
    "- **Labeling Platform Merged** (default): ~7,500+ immagini dalla piattaforma di labeling\n",
    "  - Dog-with-Leash (classe 0) - con collare/guinzaglio\n",
    "  - Dog-without-Leash (classe 1) - senza collare/guinzaglio\n",
    "- **Dog with Leash** (Roboflow, fallback): ~152 immagini\n",
    "\n",
    "## Output\n",
    "- `P(no_collar)` ‚àà [0, 1] - probabilit√† che il cane NON abbia collare\n",
    "\n",
    "## Usage\n",
    "1. Esegui `merge_exports.py` per preparare il dataset dalla piattaforma di labeling\n",
    "2. Esegui questo notebook per il training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione dipendenze\n",
    "%pip install ultralytics torch torchvision albumentations matplotlib seaborn pandas scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"Python: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione paths - RELATIVI per portabilit√†\n",
    "# Priorit√†: dataset merged dalla piattaforma di labeling, fallback a Roboflow\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "try:\n",
    "    from notebook_utils import get_paths, get_device, print_paths\n",
    "    paths = get_paths()\n",
    "    print_paths(paths)\n",
    "except ImportError:\n",
    "    print(\"notebook_utils.py non trovato, usando fallback...\")\n",
    "    # Fallback manuale\n",
    "    NOTEBOOK_DIR = Path.cwd()\n",
    "    if NOTEBOOK_DIR.name == \"notebooks\":\n",
    "        PROJECT_DIR = NOTEBOOK_DIR.parent.parent\n",
    "    elif NOTEBOOK_DIR.name == \"training\":\n",
    "        PROJECT_DIR = NOTEBOOK_DIR.parent\n",
    "    else:\n",
    "        PROJECT_DIR = NOTEBOOK_DIR\n",
    "        while PROJECT_DIR.name != \"ResQPet\" and PROJECT_DIR.parent != PROJECT_DIR:\n",
    "            PROJECT_DIR = PROJECT_DIR.parent\n",
    "    BASE_DIR = PROJECT_DIR.parent\n",
    "    paths = {\n",
    "        'project_dir': PROJECT_DIR,\n",
    "        'base_dir': BASE_DIR,\n",
    "        'weights_dir': PROJECT_DIR / \"weights\",\n",
    "        'collar_dataset': BASE_DIR / \"Dog with Leash\",\n",
    "        'runs_dir': PROJECT_DIR / \"training\" / \"runs\",\n",
    "        'notebooks_dir': PROJECT_DIR / \"training\" / \"notebooks\",\n",
    "    }\n",
    "    paths['weights_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# SELEZIONE DATASET\n",
    "# ============================================================================\n",
    "# Priorit√† 1: Dataset merged dalla piattaforma di labeling (7,500+ immagini)\n",
    "# Priorit√† 2: Dataset Roboflow \"Dog with Leash\" (152 immagini)\n",
    "\n",
    "MERGED_DATASET_DIR = paths['project_dir'] / \"labeling_data\" / \"exports\" / \"collar_yolo\"\n",
    "ROBOFLOW_DATASET_DIR = paths['collar_dataset']\n",
    "\n",
    "# Controlla se il dataset merged esiste\n",
    "if MERGED_DATASET_DIR.exists() and (MERGED_DATASET_DIR / \"data.yaml\").exists():\n",
    "    DATASET_DIR = MERGED_DATASET_DIR\n",
    "    USE_MERGED = True\n",
    "    print(\"‚úì Usando dataset MERGED dalla piattaforma di labeling\")\n",
    "elif ROBOFLOW_DATASET_DIR.exists():\n",
    "    DATASET_DIR = ROBOFLOW_DATASET_DIR\n",
    "    USE_MERGED = False\n",
    "    print(\"! Dataset merged non trovato, usando Roboflow 'Dog with Leash'\")\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nessun dataset trovato!\\n\"\n",
    "        f\"  - Merged: {MERGED_DATASET_DIR}\\n\"\n",
    "        f\"  - Roboflow: {ROBOFLOW_DATASET_DIR}\\n\\n\"\n",
    "        f\"Esegui prima: python -m labeling_tool.scripts.merge_exports\"\n",
    "    )\n",
    "\n",
    "# Assegna variabili per retrocompatibilit√†\n",
    "BASE_DIR = paths['base_dir']\n",
    "OUTPUT_DIR = paths['weights_dir']\n",
    "SPLIT_DIR = DATASET_DIR / \"split_dataset\" if not USE_MERGED else DATASET_DIR\n",
    "\n",
    "print(f\"\\nDataset: {DATASET_DIR}\")\n",
    "print(f\"Tipo: {'Merged (7,500+ img)' if USE_MERGED else 'Roboflow (152 img)'}\")\n",
    "print(f\"Output weights: {OUTPUT_DIR}\")\n",
    "print(f\"Dataset exists: {DATASET_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Esplorazione Dataset Originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizza struttura del dataset\n",
    "print(f\"Struttura dataset ({DATASET_DIR.name}):\")\n",
    "for item in sorted(DATASET_DIR.iterdir()):\n",
    "    if item.is_dir():\n",
    "        sub_items = list(item.iterdir())\n",
    "        print(f\"  {item.name}/\")\n",
    "        for sub in sub_items[:5]:\n",
    "            if sub.is_dir():\n",
    "                count = len(list(sub.glob('*.*')))\n",
    "                print(f\"      {sub.name}/ ({count} files)\")\n",
    "            else:\n",
    "                print(f\"      {sub.name}\")\n",
    "        if len(sub_items) > 5:\n",
    "            print(f\"      ... e altri {len(sub_items) - 5} elementi\")\n",
    "    else:\n",
    "        print(f\"  {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggi configurazione dataset\n",
    "data_yaml = DATASET_DIR / \"data.yaml\"\n",
    "\n",
    "if data_yaml.exists():\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        original_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"Configurazione dataset:\")\n",
    "    for key, value in original_config.items():\n",
    "        if key not in ['roboflow']:  # Skip metadata verbose\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(f\"File {data_yaml} non trovato!\")\n",
    "    original_config = {'names': {0: 'Dog-with-Leash', 1: 'Dog-without-Leash'}, 'nc': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta immagini disponibili\n",
    "if USE_MERGED:\n",
    "    # Dataset merged: immagini gi√† divise in train/val\n",
    "    train_images_dir = DATASET_DIR / 'images' / 'train'\n",
    "    train_labels_dir = DATASET_DIR / 'labels' / 'train'\n",
    "    val_images_dir = DATASET_DIR / 'images' / 'val'\n",
    "    val_labels_dir = DATASET_DIR / 'labels' / 'val'\n",
    "    \n",
    "    train_images = list(train_images_dir.glob('*.jpg')) + list(train_images_dir.glob('*.png'))\n",
    "    val_images = list(val_images_dir.glob('*.jpg')) + list(val_images_dir.glob('*.png'))\n",
    "    all_images = train_images + val_images\n",
    "    \n",
    "    print(f\"Immagini trovate:\")\n",
    "    print(f\"  - Train: {len(train_images)}\")\n",
    "    print(f\"  - Val: {len(val_images)}\")\n",
    "    print(f\"  - Totale: {len(all_images)}\")\n",
    "    \n",
    "    # Verifica labels\n",
    "    train_with_labels = sum(1 for img in train_images if (train_labels_dir / f\"{img.stem}.txt\").exists())\n",
    "    val_with_labels = sum(1 for img in val_images if (val_labels_dir / f\"{img.stem}.txt\").exists())\n",
    "    print(f\"\\nImmagini con labels:\")\n",
    "    print(f\"  - Train: {train_with_labels}\")\n",
    "    print(f\"  - Val: {val_with_labels}\")\n",
    "else:\n",
    "    # Dataset Roboflow: solo cartella train\n",
    "    train_images_dir = DATASET_DIR / 'train' / 'images'\n",
    "    train_labels_dir = DATASET_DIR / 'train' / 'labels'\n",
    "    \n",
    "    all_images = list(train_images_dir.glob('*.jpg')) + list(train_images_dir.glob('*.png'))\n",
    "    print(f\"Immagini trovate: {len(all_images)}\")\n",
    "    \n",
    "    # Verifica labels\n",
    "    images_with_labels = sum(1 for img in all_images if (train_labels_dir / f\"{img.stem}.txt\").exists())\n",
    "    print(f\"Immagini con labels: {images_with_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizza distribuzione classi\n",
    "class_counts = {0: 0, 1: 0}  # 0=with-leash, 1=without-leash\n",
    "\n",
    "if USE_MERGED:\n",
    "    # Analizza sia train che val\n",
    "    label_dirs = [\n",
    "        DATASET_DIR / 'labels' / 'train',\n",
    "        DATASET_DIR / 'labels' / 'val'\n",
    "    ]\n",
    "else:\n",
    "    label_dirs = [DATASET_DIR / 'train' / 'labels']\n",
    "\n",
    "for label_dir in label_dirs:\n",
    "    if not label_dir.exists():\n",
    "        continue\n",
    "    for label_file in label_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    cls = int(parts[0])\n",
    "                    if cls in class_counts:\n",
    "                        class_counts[cls] += 1\n",
    "\n",
    "print(\"\\nDistribuzione classi:\")\n",
    "class_names = original_config.get('names', {0: 'Dog-with-Leash', 1: 'Dog-without-Leash'})\n",
    "if isinstance(class_names, list):\n",
    "    class_names = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "for cls, count in class_counts.items():\n",
    "    name = class_names.get(cls, f\"Class {cls}\")\n",
    "    print(f\"  {name}: {count} annotazioni\")\n",
    "\n",
    "# Visualizza\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar([class_names[0], class_names[1]], [class_counts[0], class_counts[1]], \n",
    "        color=['green', 'red'])\n",
    "plt.title('Distribuzione Classi nel Dataset')\n",
    "plt.ylabel('Numero annotazioni')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza alcune immagini di esempio\n",
    "import cv2\n",
    "\n",
    "# Seleziona immagini da visualizzare\n",
    "if USE_MERGED:\n",
    "    sample_dir = DATASET_DIR / 'images' / 'train'\n",
    "    labels_dir = DATASET_DIR / 'labels' / 'train'\n",
    "else:\n",
    "    sample_dir = DATASET_DIR / 'train' / 'images'\n",
    "    labels_dir = DATASET_DIR / 'train' / 'labels'\n",
    "\n",
    "sample_images = sorted(sample_dir.glob('*.jpg'))[:6]\n",
    "if len(sample_images) < 6:\n",
    "    sample_images += sorted(sample_dir.glob('*.png'))[:6 - len(sample_images)]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img_path in enumerate(sample_images):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Carica annotation\n",
    "    label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(img_path.name, fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Mostra bbox\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    cls = int(parts[0])\n",
    "                    cx, cy, w, h = float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                    \n",
    "                    # Convert YOLO format to pixels\n",
    "                    img_h, img_w = img.shape[:2]\n",
    "                    x1 = int((cx - w/2) * img_w)\n",
    "                    y1 = int((cy - h/2) * img_h)\n",
    "                    box_w = int(w * img_w)\n",
    "                    box_h = int(h * img_h)\n",
    "                    \n",
    "                    color = 'green' if cls == 0 else 'red'  # 0=with-leash, 1=without\n",
    "                    label = 'With Collar' if cls == 0 else 'Without Collar'\n",
    "                    rect = plt.Rectangle((x1, y1), box_w, box_h, \n",
    "                                         fill=False, edgecolor=color, linewidth=2)\n",
    "                    axes[i].add_patch(rect)\n",
    "                    axes[i].text(x1, y1-5, label, color=color, fontsize=8, \n",
    "                                fontweight='bold', backgroundcolor='white')\n",
    "\n",
    "# Nascondi assi vuoti\n",
    "for j in range(len(sample_images), 6):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "dataset_name = \"Merged Dataset\" if USE_MERGED else \"Roboflow Dataset\"\n",
    "plt.suptitle(f'Esempi dal {dataset_name}', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(paths['notebooks_dir'] / 'collar_dataset_samples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Creazione Split Train/Val/Test\n",
    "\n",
    "**Nota**: Se stai usando il dataset merged dalla piattaforma di labeling, lo split √® gi√† stato fatto dal merge script (80% train, 20% val).\n",
    "\n",
    "Se invece stai usando il dataset Roboflow (che ha solo `train`), creiamo uno split:\n",
    "- Train: 70%\n",
    "- Validation: 20%\n",
    "- Test: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MERGED:\n",
    "    # Dataset merged gi√† ha train/val split - skip creazione\n",
    "    print(\"‚úì Dataset merged gi√† contiene split train/val\")\n",
    "    print(f\"  - Train: {len(train_images)} immagini\")\n",
    "    print(f\"  - Val: {len(val_images)} immagini\")\n",
    "    \n",
    "    # Stats per compatibilit√† con celle successive\n",
    "    stats = {\n",
    "        'train': len(train_images),\n",
    "        'valid': len(val_images),\n",
    "        'test': 0  # Non c'√® test set nel merged\n",
    "    }\n",
    "    \n",
    "    # Config path √® gi√† il data.yaml del dataset merged\n",
    "    config_path = DATASET_DIR / 'data.yaml'\n",
    "    \n",
    "else:\n",
    "    # Dataset Roboflow: crea split manualmente\n",
    "    def create_dataset_split(images, labels_dir, output_dir, train_ratio=0.7, val_ratio=0.2, seed=42):\n",
    "        \"\"\"Crea split train/val/test del dataset\"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        images = list(images)\n",
    "        random.shuffle(images)\n",
    "        \n",
    "        n = len(images)\n",
    "        train_end = int(n * train_ratio)\n",
    "        val_end = int(n * (train_ratio + val_ratio))\n",
    "        \n",
    "        splits = {\n",
    "            'train': images[:train_end],\n",
    "            'valid': images[train_end:val_end],\n",
    "            'test': images[val_end:]\n",
    "        }\n",
    "        \n",
    "        print(f\"Split dataset:\")\n",
    "        print(f\"  Train: {len(splits['train'])} images ({len(splits['train'])/n*100:.1f}%)\")\n",
    "        print(f\"  Valid: {len(splits['valid'])} images ({len(splits['valid'])/n*100:.1f}%)\")\n",
    "        print(f\"  Test:  {len(splits['test'])} images ({len(splits['test'])/n*100:.1f}%)\")\n",
    "        \n",
    "        for split_name, split_images in splits.items():\n",
    "            img_dir = output_dir / split_name / 'images'\n",
    "            lbl_dir = output_dir / split_name / 'labels'\n",
    "            img_dir.mkdir(parents=True, exist_ok=True)\n",
    "            lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for img_path in split_images:\n",
    "                shutil.copy(img_path, img_dir / img_path.name)\n",
    "                label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "                if label_path.exists():\n",
    "                    shutil.copy(label_path, lbl_dir / label_path.name)\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    # Rimuovi split precedente se esiste\n",
    "    if SPLIT_DIR.exists():\n",
    "        print(f\"Rimuovo split precedente: {SPLIT_DIR}\")\n",
    "        shutil.rmtree(SPLIT_DIR)\n",
    "\n",
    "    print(f\"\\nCreazione split in: {SPLIT_DIR}\")\n",
    "    splits = create_dataset_split(all_images, train_labels_dir, SPLIT_DIR)\n",
    "    \n",
    "    stats = {\n",
    "        'train': len(splits['train']),\n",
    "        'valid': len(splits['valid']),\n",
    "        'test': len(splits['test'])\n",
    "    }\n",
    "\n",
    "    print(f\"\\n‚úì Split completato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dataset\n",
    "print(\"Verifica dataset:\")\n",
    "\n",
    "if USE_MERGED:\n",
    "    # Verifica struttura merged\n",
    "    for split in ['train', 'val']:\n",
    "        img_dir = DATASET_DIR / 'images' / split\n",
    "        lbl_dir = DATASET_DIR / 'labels' / split\n",
    "        \n",
    "        n_images = len(list(img_dir.glob('*.*')))\n",
    "        n_labels = len(list(lbl_dir.glob('*.txt')))\n",
    "        \n",
    "        print(f\"  {split}: {n_images} images, {n_labels} labels\")\n",
    "    \n",
    "    print(f\"\\nTotale: {stats['train'] + stats['valid']} images\")\n",
    "else:\n",
    "    # Verifica split creato\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        img_dir = SPLIT_DIR / split / 'images'\n",
    "        lbl_dir = SPLIT_DIR / split / 'labels'\n",
    "        \n",
    "        n_images = len(list(img_dir.glob('*.*')))\n",
    "        n_labels = len(list(lbl_dir.glob('*.txt')))\n",
    "        \n",
    "        stats[split] = n_images\n",
    "        print(f\"  {split}: {n_images} images, {n_labels} labels\")\n",
    "\n",
    "    print(f\"\\nTotale: {sum(stats.values())} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configurazione YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione YAML per training\n",
    "if USE_MERGED:\n",
    "    # Usa il data.yaml esistente del dataset merged\n",
    "    config_path = DATASET_DIR / 'data.yaml'\n",
    "    print(f\"Usando config esistente: {config_path}\")\n",
    "    \n",
    "    with open(config_path, 'r') as f:\n",
    "        training_config = yaml.safe_load(f)\n",
    "else:\n",
    "    # Crea file di configurazione YAML per dataset Roboflow splittato\n",
    "    training_config = {\n",
    "        'path': str(SPLIT_DIR),\n",
    "        'train': 'train/images',\n",
    "        'val': 'valid/images',\n",
    "        'test': 'test/images',\n",
    "        'names': {\n",
    "            0: 'Dog-with-Leash',\n",
    "            1: 'Dog-without-Leash'\n",
    "        },\n",
    "        'nc': 2\n",
    "    }\n",
    "\n",
    "    config_path = SPLIT_DIR / 'data.yaml'\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump(training_config, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"Config salvata in: {config_path}\")\n",
    "\n",
    "print(\"\\nContenuto config:\")\n",
    "with open(config_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training YOLOv8n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica modello pre-trained\n",
    "print(\"Caricamento YOLOv8n pre-trained...\")\n",
    "model = YOLO('yolov8n.pt')  # Nano version for speed\n",
    "print(\"Modello caricato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione training\n",
    "# Parametri adattati in base alla dimensione del dataset e hardware\n",
    "\n",
    "# Assicurati che stats esista\n",
    "if 'stats' not in dir():\n",
    "    if USE_MERGED:\n",
    "        train_count = len(list((DATASET_DIR / 'images' / 'train').glob('*.*')))\n",
    "        val_count = len(list((DATASET_DIR / 'images' / 'val').glob('*.*')))\n",
    "        stats = {'train': train_count, 'valid': val_count, 'test': 0}\n",
    "    else:\n",
    "        stats = {'train': 0, 'valid': 0, 'test': 0}\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURAZIONE HARDWARE\n",
    "# ============================================================================\n",
    "# Rileva automaticamente le GPU disponibili\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    NUM_GPUS = torch.cuda.device_count()\n",
    "    GPU_NAMES = [torch.cuda.get_device_name(i) for i in range(NUM_GPUS)]\n",
    "    TOTAL_VRAM = sum(torch.cuda.get_device_properties(i).total_memory for i in range(NUM_GPUS)) / 1e9\n",
    "    \n",
    "    print(f\"üñ•Ô∏è  GPU rilevate: {NUM_GPUS}\")\n",
    "    for i, name in enumerate(GPU_NAMES):\n",
    "        vram = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "        print(f\"   [{i}] {name} ({vram:.0f}GB)\")\n",
    "    \n",
    "    # Configura device per multi-GPU\n",
    "    if NUM_GPUS >= 2:\n",
    "        DEVICE = list(range(NUM_GPUS))  # [0, 1] per 2 GPU\n",
    "        BATCH_SIZE = 128  # 64 per GPU con 2x 5090\n",
    "        WORKERS = 8\n",
    "        print(f\"\\n‚úì Multi-GPU attivo: {DEVICE}\")\n",
    "    else:\n",
    "        DEVICE = 0\n",
    "        BATCH_SIZE = 64\n",
    "        WORKERS = 4\n",
    "        \n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    BATCH_SIZE = 16\n",
    "    WORKERS = 4\n",
    "    NUM_GPUS = 1\n",
    "    print(\"üçé Apple Silicon MPS\")\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    BATCH_SIZE = 8\n",
    "    WORKERS = 2\n",
    "    NUM_GPUS = 0\n",
    "    print(\"‚ö†Ô∏è  Nessuna GPU, usando CPU\")\n",
    "\n",
    "# ============================================================================\n",
    "# PARAMETRI TRAINING\n",
    "# ============================================================================\n",
    "if USE_MERGED:\n",
    "    EPOCHS = 100\n",
    "    PATIENCE = 20\n",
    "else:\n",
    "    EPOCHS = 150\n",
    "    PATIENCE = 30\n",
    "\n",
    "IMG_SIZE = 640\n",
    "\n",
    "training_args = {\n",
    "    'data': str(config_path),\n",
    "    'epochs': EPOCHS,\n",
    "    'batch': BATCH_SIZE,\n",
    "    'imgsz': IMG_SIZE,\n",
    "    'patience': PATIENCE,\n",
    "    'save': True,\n",
    "    'save_period': 20,\n",
    "    'device': DEVICE,\n",
    "    'workers': WORKERS,\n",
    "    'project': str(paths['runs_dir']),\n",
    "    'name': 'collar_detector',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.001,\n",
    "    'lrf': 0.01,\n",
    "    'weight_decay': 0.0005,\n",
    "    'amp': True,  # Mixed precision FP16 per velocit√†\n",
    "    \n",
    "    # Cache dataset in RAM se disponibile (velocizza training)\n",
    "    # 'cache': 'ram',  # Decommentare se hai 64GB+ RAM\n",
    "    \n",
    "    # Augmentation (meno aggressiva per dataset grande)\n",
    "    'hsv_h': 0.02,\n",
    "    'hsv_s': 0.7 if USE_MERGED else 0.8,\n",
    "    'hsv_v': 0.4 if USE_MERGED else 0.5,\n",
    "    'degrees': 15 if USE_MERGED else 20,\n",
    "    'translate': 0.1 if USE_MERGED else 0.15,\n",
    "    'scale': 0.5 if USE_MERGED else 0.6,\n",
    "    'shear': 5 if USE_MERGED else 10,\n",
    "    'perspective': 0.0005,\n",
    "    'flipud': 0.2 if USE_MERGED else 0.3,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.1 if USE_MERGED else 0.2,\n",
    "    'copy_paste': 0.05 if USE_MERGED else 0.1,\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CONFIGURAZIONE TRAINING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Dataset:      {stats['train']} train, {stats['valid']} val\")\n",
    "print(f\"Device:       {DEVICE} ({NUM_GPUS} GPU)\")\n",
    "print(f\"Batch size:   {BATCH_SIZE}\")\n",
    "print(f\"Epochs:       {EPOCHS}\")\n",
    "print(f\"Image size:   {IMG_SIZE}\")\n",
    "print(f\"Workers:      {WORKERS}\")\n",
    "print(f\"Mixed Prec:   {training_args['amp']}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "print(\"=\"*60)\n",
    "print(\"INIZIO TRAINING COLLAR DETECTOR\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Dataset: {stats['train']} train, {stats['valid']} val\")\n",
    "print()\n",
    "\n",
    "# Esegui training\n",
    "results = model.train(**training_args)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETATO!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Valutazione Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il best model\n",
    "results_dir = paths['runs_dir'] / 'collar_detector'\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "\n",
    "print(f\"Cercando modello in: {best_model_path}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    best_model = YOLO(str(best_model_path))\n",
    "    print(f\"‚úì Best model caricato da: {best_model_path}\")\n",
    "else:\n",
    "    # Prova path alternativo\n",
    "    alt_path = paths['project_dir'] / 'training' / 'runs' / 'collar_detector' / 'weights' / 'best.pt'\n",
    "    if alt_path.exists():\n",
    "        best_model_path = alt_path\n",
    "        best_model = YOLO(str(best_model_path))\n",
    "        print(f\"‚úì Best model caricato da path alternativo: {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Best model non trovato in:\")\n",
    "        print(f\"   - {best_model_path}\")\n",
    "        print(f\"   - {alt_path}\")\n",
    "        print(\"Usando il modello corrente...\")\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione su validation set\n",
    "print(\"Valutazione su validation set...\")\n",
    "val_results = best_model.val(data=str(config_path))\n",
    "\n",
    "print(\"\\nMetriche:\")\n",
    "print(f\"  mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"  mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"  Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"  Recall: {val_results.box.mr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza curve di training\n",
    "results_csv = results_dir / 'results.csv'\n",
    "\n",
    "print(f\"Cercando risultati in: {results_csv}\")\n",
    "\n",
    "if results_csv.exists():\n",
    "    df_results = pd.read_csv(results_csv)\n",
    "    df_results.columns = df_results.columns.str.strip()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Box Loss\n",
    "    if 'train/box_loss' in df_results.columns:\n",
    "        axes[0, 0].plot(df_results['train/box_loss'], label='Train', color='blue')\n",
    "        if 'val/box_loss' in df_results.columns:\n",
    "            axes[0, 0].plot(df_results['val/box_loss'], label='Val', color='orange')\n",
    "        axes[0, 0].set_title('Box Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # mAP\n",
    "    if 'metrics/mAP50(B)' in df_results.columns:\n",
    "        axes[0, 1].plot(df_results['metrics/mAP50(B)'], label='mAP50', color='green')\n",
    "        if 'metrics/mAP50-95(B)' in df_results.columns:\n",
    "            axes[0, 1].plot(df_results['metrics/mAP50-95(B)'], label='mAP50-95', color='purple')\n",
    "        axes[0, 1].set_title('mAP Metrics')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision/Recall\n",
    "    if 'metrics/precision(B)' in df_results.columns:\n",
    "        axes[1, 0].plot(df_results['metrics/precision(B)'], label='Precision', color='blue')\n",
    "        axes[1, 0].plot(df_results['metrics/recall(B)'], label='Recall', color='red')\n",
    "        axes[1, 0].set_title('Precision & Recall')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Class Loss\n",
    "    if 'train/cls_loss' in df_results.columns:\n",
    "        axes[1, 1].plot(df_results['train/cls_loss'], label='Train', color='blue')\n",
    "        if 'val/cls_loss' in df_results.columns:\n",
    "            axes[1, 1].plot(df_results['val/cls_loss'], label='Val', color='orange')\n",
    "        axes[1, 1].set_title('Classification Loss')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = results_dir / 'training_curves.png'\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    print(f\"‚úì Salvato: {save_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Results CSV non trovato in {results_csv}\")\n",
    "    print(f\"   Verifica: ls {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test su immagini del validation/test set\n",
    "if USE_MERGED:\n",
    "    test_images_dir = DATASET_DIR / 'images' / 'val'  # Usa val per test\n",
    "else:\n",
    "    test_images_dir = SPLIT_DIR / 'test' / 'images'\n",
    "\n",
    "test_images = list(test_images_dir.glob('*.*'))[:6]\n",
    "\n",
    "if test_images:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(test_images):\n",
    "        # Inference\n",
    "        results = best_model(str(img_path), verbose=False)\n",
    "        \n",
    "        # Visualizza con annotazioni\n",
    "        annotated = results[0].plot()\n",
    "        annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[i].imshow(annotated)\n",
    "        axes[i].set_title(img_path.name, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Nascondi assi vuoti\n",
    "    for j in range(len(test_images), 6):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Predizioni su Validation Set', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva nella directory corretta\n",
    "    save_path = results_dir / 'test_predictions.png'\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    print(f\"‚úì Salvato: {save_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nessuna immagine nel validation/test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia il best model nella cartella weights del progetto\n",
    "final_model_path = OUTPUT_DIR / 'collar_detector.pt'\n",
    "\n",
    "print(f\"Cercando best model in: {best_model_path}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    shutil.copy(best_model_path, final_model_path)\n",
    "    print(f\"‚úì Modello salvato in: {final_model_path}\")\n",
    "    print(f\"  Dimensione: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    # Prova last.pt\n",
    "    last_model_path = best_model_path.parent / 'last.pt'\n",
    "    if last_model_path.exists():\n",
    "        shutil.copy(last_model_path, final_model_path)\n",
    "        print(f\"‚úì Last model salvato in: {final_model_path}\")\n",
    "        print(f\"  Dimensione: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Nessun modello trovato!\")\n",
    "        print(f\"   Verifica manualmente: {results_dir / 'weights'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test finale del modello esportato\n",
    "if final_model_path.exists():\n",
    "    print(\"Test modello esportato...\")\n",
    "    \n",
    "    exported_model = YOLO(str(final_model_path))\n",
    "    \n",
    "    # Test su un'immagine\n",
    "    if test_images:\n",
    "        test_result = exported_model(str(test_images[0]), verbose=False)\n",
    "        \n",
    "        print(f\"\\nTest su: {test_images[0].name}\")\n",
    "        print(f\"Detections: {len(test_result[0].boxes)}\")\n",
    "        \n",
    "        for box in test_result[0].boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = training_config['names'][cls]\n",
    "            print(f\"  - {cls_name}: {conf:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione helper per ottenere P(no_collar)\n",
    "def get_no_collar_probability(model, image_path):\n",
    "    \"\"\"\n",
    "    Analizza un'immagine e ritorna P(no_collar)\n",
    "    \n",
    "    Returns:\n",
    "        float: probabilit√† che il cane NON abbia collare [0, 1]\n",
    "    \"\"\"\n",
    "    results = model(image_path, verbose=False)\n",
    "    \n",
    "    # Se non ci sono detection, assumiamo incertezza\n",
    "    if len(results[0].boxes) == 0:\n",
    "        return 0.7  # Default: probabilmente senza collare (non rilevato)\n",
    "    \n",
    "    # Prendi la detection con confidence pi√π alta\n",
    "    best_conf = 0\n",
    "    best_cls = None\n",
    "    \n",
    "    for box in results[0].boxes:\n",
    "        conf = float(box.conf[0])\n",
    "        if conf > best_conf:\n",
    "            best_conf = conf\n",
    "            best_cls = int(box.cls[0])\n",
    "    \n",
    "    # Classe 0 = con guinzaglio, Classe 1 = senza guinzaglio\n",
    "    if best_cls == 0:  # Dog-with-Leash\n",
    "        return 1.0 - best_conf  # Bassa probabilit√† di essere senza\n",
    "    else:  # Dog-without-Leash\n",
    "        return best_conf  # Alta probabilit√† di essere senza\n",
    "\n",
    "# Test\n",
    "if test_images and final_model_path.exists():\n",
    "    print(\"\\nTest funzione get_no_collar_probability:\")\n",
    "    for img_path in test_images[:3]:\n",
    "        p_no_collar = get_no_collar_probability(exported_model, str(img_path))\n",
    "        print(f\"  {img_path.name}: P(no_collar) = {p_no_collar:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riepilogo finale\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RIEPILOGO TRAINING COLLAR DETECTOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset: {'Merged (Piattaforma Labeling)' if USE_MERGED else 'Roboflow Dog with Leash'}\")\n",
    "print(f\"   Path: {DATASET_DIR}\")\n",
    "print(f\"   - Train: {stats.get('train', 0)} images\")\n",
    "print(f\"   - Valid: {stats.get('valid', 0)} images\")\n",
    "if not USE_MERGED:\n",
    "    print(f\"   - Test:  {stats.get('test', 0)} images\")\n",
    "\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"   - Model: YOLOv8n\")\n",
    "print(f\"   - Epochs: {EPOCHS}\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   - Image size: {IMG_SIZE}\")\n",
    "\n",
    "print(f\"\\nRisultati:\")\n",
    "print(f\"   - mAP50: {val_results.box.map50:.4f}\")\n",
    "print(f\"   - mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(f\"   - Precision: {val_results.box.mp:.4f}\")\n",
    "print(f\"   - Recall: {val_results.box.mr:.4f}\")\n",
    "\n",
    "print(f\"\\nModello salvato: {final_model_path}\")\n",
    "if final_model_path.exists():\n",
    "    print(f\"   Dimensione: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Per usare il modello:\")\n",
    "print(f\"  from ultralytics import YOLO\")\n",
    "print(f\"  model = YOLO('{final_model_path}')\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
